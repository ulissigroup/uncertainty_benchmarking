{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is built upon its counterpart in the `BNN` folder, and the only difference between the two versions is that this notebook allows a specified amount of dropout to be applied to the training, validation and testing stages of the ensembling process.\n",
    "\n",
    "Please specify here the amount of dropout you wish to apply to the training, validation and testing stages of the ensembling. A default value of 0.20 is used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_amount = 0.20\n",
    "dropout_int = int(dropout_amount * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import os, sys\n",
    "import numpy as np\n",
    "#Select which GPU to use if necessary\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "# import mongo\n",
    "import time\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Bayesian CGCNN'\n",
    "\n",
    "with open('../../preprocessing/sdt/gasdb/feature_dimensions.pkl', 'rb') as file_handle:\n",
    "    orig_atom_fea_len, nbr_fea_len = pickle.load(file_handle)\n",
    "\n",
    "with open('../../preprocessing/splits_gasdb.pkl', 'rb') as file_handle:\n",
    "    splits = pickle.load(file_handle)\n",
    "\n",
    "docs_train, docs_val, docs_test = splits['docs_train'], splits['docs_val'], splits['docs_test']\n",
    "sdts_train, sdts_val, sdts_test = splits['sdts_train'], splits['sdts_val'], splits['sdts_test']\n",
    "targets_train, targets_val, targets_test = splits['targets_train'], splits['targets_val'], splits['targets_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This requires a modified version of the CGCNN package, which is available at `https://github.com/ulissigroup/cgcnn/tree/dropout`.  We assume this version of the CGCNN module is installed under the `$HOME/cgcnn` directory. If this is not the case, please modify the first line in the cell below to the directory where CGCNN is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cpu\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(os.path.expanduser(\"~/cgcnn\"))\n",
    "\n",
    "from torch.optim import Adam, SGD\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from skorch.callbacks import Checkpoint, LoadInitState #needs skorch >= 0.4.0\n",
    "from cgcnn.data import collate_pool, MergeDataset\n",
    "try:\n",
    "    from cgcnn.model_pyro import CrystalGraphConvNet # Same model but different names for layers\n",
    "except ModuleNotFoundError:\n",
    "    from model_pyro import CrystalGraphConvNet\n",
    "from skorch import NeuralNetRegressor\n",
    "import torch\n",
    "import skorch.callbacks.base\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device='cpu'\n",
    "print('device', device)\n",
    "\n",
    "\n",
    "# Update dropout value with input\n",
    "if dropout_amount != 0:\n",
    "    CrystalGraphConvNet.update_dropout(True, dropout_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize GCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'adamwr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f5aa97c96872>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCVSplit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWarmRestartLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLRScheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0madamwr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madamw\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0madamwr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_scheduler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCosineLRWithRestarts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'adamwr'"
     ]
    }
   ],
   "source": [
    "from skorch.dataset import CVSplit\n",
    "from skorch.callbacks.lr_scheduler import WarmRestartLR, LRScheduler\n",
    "from adamwr.adamw import AdamW\n",
    "from adamwr.cosine_scheduler import CosineLRWithRestarts\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skorch import callbacks\n",
    "train_test_splitter = ShuffleSplit(test_size=0.25, random_state=42)\n",
    "\n",
    "#Make a checkpoint to save parameters every time there is a new best for validation lost\n",
    "cp = Checkpoint(monitor='valid_loss_best',fn_prefix='d%i_valid_best_' % dropout_int)\n",
    "\n",
    "#Callback to load the checkpoint with the best validation loss at the end of training\n",
    "\n",
    "class train_end_load_best_valid_loss(skorch.callbacks.base.Callback):\n",
    "    def on_train_end(self, net, X, y):\n",
    "        net.load_params('d%i_valid_best_params.pt' % dropout_int)\n",
    "        \n",
    "load_best_valid_loss = train_end_load_best_valid_loss()\n",
    "\n",
    "LR_schedule = callbacks.lr_scheduler.LRScheduler('MultiStepLR', milestones=[100], gamma=0.1)\n",
    "\n",
    "#############\n",
    "# To extract intermediate features, set the forward takes only the first return value to calculate loss\n",
    "class MyNet(NeuralNetRegressor):\n",
    "    def get_loss(self, y_pred, y_true, **kwargs):\n",
    "        y_pred = y_pred[0] if isinstance(y_pred, tuple) else y_pred  # discard the 2nd output\n",
    "        return super().get_loss(y_pred, y_true, **kwargs)\n",
    "## return features = net.forward(SDT_test)\n",
    "############\n",
    "\n",
    "net = MyNet(\n",
    "    CrystalGraphConvNet,\n",
    "    module__orig_atom_fea_len = orig_atom_fea_len,\n",
    "    module__nbr_fea_len = nbr_fea_len,\n",
    "    batch_size=214,\n",
    "    module__classification=False,\n",
    "    lr=0.0056,\n",
    "    max_epochs= 30, \n",
    "    module__atom_fea_len=46,\n",
    "    module__h_fea_len=83,\n",
    "    module__n_conv=8, #8\n",
    "    module__n_h=4,\n",
    "    optimizer__weight_decay=1e-5,\n",
    "    optimizer=AdamW,\n",
    "    iterator_train__pin_memory=True,\n",
    "    iterator_train__num_workers=0,\n",
    "    iterator_train__collate_fn = collate_pool,\n",
    "    iterator_valid__pin_memory=True,\n",
    "    iterator_valid__num_workers=0,\n",
    "    iterator_valid__collate_fn = collate_pool,\n",
    "    device=device,\n",
    "#     criterion=torch.nn.MSELoss,\n",
    "    criterion=torch.nn.L1Loss,\n",
    "    dataset=MergeDataset,\n",
    "#     train_split = CVSplit(cv=train_test_splitter),\n",
    "    callbacks=[cp, load_best_valid_loss, LR_schedule]\n",
    ")\n",
    "\n",
    "net.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Pyro model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "from pyro.distributions import Normal, Categorical, Uniform\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam, AdamW\n",
    "pyro.enable_validation(True)\n",
    "\n",
    "def model(x_data, y_data):\n",
    "    priors = dict()\n",
    "    for n, p in net.module_.named_parameters():\n",
    "        if \"fcs\" in n:\n",
    "            i = 2\n",
    "        elif \"conv\" in n and \"fc_full\" in n:\n",
    "            i = 2\n",
    "        elif \"conv\" in n and \"bn\" in n:\n",
    "            i = 1\n",
    "\n",
    "        if \"weight\" in n:\n",
    "            priors[n] = pyro.distributions.Normal(\n",
    "                    loc   = torch.zeros_like(p),\n",
    "                    scale = torch.ones_like(p)).independent(i)\n",
    "        elif \"bias\" in n:\n",
    "            priors[n] = pyro.distributions.Normal(\n",
    "                    loc   = torch.zeros_like(p),\n",
    "                    scale = torch.ones_like(p)).independent(1)\n",
    "    # lift module parameters to random variables sampled from the priors\n",
    "    dist = {\"fcs_out.weight\": priors[\"fcs_out.weight\"], \"fcs_out.bias\": priors[\"fcs_out.bias\"],\n",
    "           \"fcs2.weight\": priors[\"fcs2.weight\"], \"fcs2.bias\": priors[\"fcs2.bias\"],\n",
    "           \"fcs1.weight\": priors[\"fcs1.weight\"], \"fcs1.bias\": priors[\"fcs1.bias\"],\n",
    "           \"fcs0.weight\": priors[\"fcs0.weight\"], \"fcs0.bias\": priors[\"fcs0.bias\"],\n",
    "           \"fcs_linear.weight\": priors[\"fcs_linear.weight\"], \"fcs_linear.bias\": priors[\"fcs_linear.bias\"]}\n",
    "    \n",
    "    \n",
    "    \n",
    "    lifted_module = pyro.random_module(\"module\", net.module_, dist)\n",
    "    # sample a regressor (which also samples w and b)\n",
    "    lifted_reg_model = lifted_module()\n",
    "    with pyro.iarange(\"map\", len(x_data)):\n",
    "        predicted_target = lifted_reg_model(x_data, y_data)\n",
    "        # condition on the observed data\n",
    "        pyro.sample(\"obs\",\n",
    "                    Normal(predicted_target, 0.1*torch.ones_like(torch.tensor(y_data))).independent(2),\n",
    "                    obs=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softplus = torch.nn.Softplus()\n",
    "\n",
    "def guide(x_data, y_data):\n",
    "\n",
    "    priors = dict()\n",
    "    for n, p in net.module_.named_parameters():\n",
    "        if \"fcs\" in n:\n",
    "            i = 2\n",
    "        elif \"conv\" in n and \"fc_full\" in n:\n",
    "            i = 2\n",
    "        elif \"conv\" in n and \"bn\" in n:\n",
    "            i = 1\n",
    "\n",
    "        if \"weight\" in n:\n",
    "            loc   = pyro.param(\"mu_\"    + n, torch.randn_like(p))\n",
    "            scale = torch.abs(pyro.param(\"sigma_\" + n, softplus(torch.randn_like(p))))\n",
    "            priors[n] = pyro.distributions.Normal(loc = loc, scale = scale).independent(i)\n",
    "        elif \"bias\" in n:\n",
    "            loc       = pyro.param(\"mu_\"    + n, torch.randn_like(p))\n",
    "            scale     = torch.abs(pyro.param(\"sigma_\" + n, softplus(torch.randn_like(p))))\n",
    "            priors[n] = pyro.distributions.Normal(loc = loc, scale = scale).independent(1)\n",
    "                \n",
    "    dist = {\"fcs_out.weight\": priors[\"fcs_out.weight\"], \"fcs_out.bias\": priors[\"fcs_out.bias\"],\n",
    "           \"fcs2.weight\": priors[\"fcs2.weight\"], \"fcs2.bias\": priors[\"fcs2.bias\"],\n",
    "           \"fcs1.weight\": priors[\"fcs1.weight\"], \"fcs1.bias\": priors[\"fcs1.bias\"],\n",
    "           \"fcs0.weight\": priors[\"fcs0.weight\"], \"fcs0.bias\": priors[\"fcs0.bias\"],\n",
    "           \"fcs_linear.weight\": priors[\"fcs_linear.weight\"], \"fcs_linear.bias\": priors[\"fcs_linear.bias\"]}\n",
    "    lifted_module = pyro.random_module(\"module\", net.module_, dist)\n",
    "    # sample a regressor (which also samples w and b)\n",
    "    return lifted_module()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 48\n",
    "batch_x_train, batch_y_train = [],[]\n",
    "batch_train, batch_val, batch_test =[], [], []\n",
    "\n",
    "for i in range(0, len(sdts_train), batch_size):\n",
    "    batch_x_train.append(sdts_train[i:i+batch_size])\n",
    "    batch_y_train.append(targets_train[i:i+batch_size])\n",
    "    batch_train.append((sdts_train[i:i+batch_size], targets_train[i:i+batch_size]))\n",
    "\n",
    "batch_x_val, batch_y_val = [],[]\n",
    "for i in range(0, len(sdts_val), batch_size):\n",
    "    batch_x_val.append(sdts_val[i:i+batch_size])\n",
    "    batch_y_val.append(targets_val[i:i+batch_size])\n",
    "    batch_val.append((sdts_val[i:i+batch_size], targets_val[i:i+batch_size]))\n",
    "    \n",
    "\n",
    "batch_x_test, batch_y_test = [],[]\n",
    "for i in range(0, len(sdts_test), batch_size):\n",
    "    batch_x_test.append(sdts_test[i:i+batch_size])\n",
    "    batch_y_test.append(targets_test[i:i+batch_size])\n",
    "    batch_test.append((sdts_test[i:i+batch_size], targets_test[i:i+batch_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import tqdm\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# import random\n",
    "\n",
    "# num_iterations = 1000\n",
    "# loss = 0\n",
    "# start_loss = 600\n",
    "# epoch = 0\n",
    "# lr = 0.01\n",
    "# # optimizer = Adam({\"lr\":lr})\n",
    "# optimizer = AdamW({\"lr\":lr})\n",
    "\n",
    "# svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "# for j in range(num_iterations):\n",
    "#     loss = 0\n",
    "#     # Shuffle training example each epoch\n",
    "#     shuffle_idx = np.random.permutation(np.arange(len(sdts_train)))\n",
    "#     shuffled_sdts_train, shuffled_targets_train = [], []\n",
    "#     for idx in shuffle_idx:\n",
    "#         idx = int(idx)\n",
    "#         shuffled_sdts_train.append(sdts_train[idx])\n",
    "#         shuffled_targets_train.append(targets_train[idx])\n",
    "#     shuffled_targets_train = np.array(shuffled_targets_train)\n",
    "#     batch_train = []\n",
    "#     for i in range(0, len(shuffled_sdts_train), batch_size):\n",
    "#         batch_train.append((shuffled_sdts_train[i:i+batch_size], shuffled_targets_train[i:i+batch_size]))\n",
    "\n",
    "#     for batch_id, data in enumerate(batch_train):\n",
    "#         loss += svi.step(data[0], torch.tensor(data[1]))\n",
    "#     normalizer_train = len(sdts_train)\n",
    "#     total_epoch_loss_train = loss / normalizer_train\n",
    "    \n",
    "#     if total_epoch_loss_train < start_loss:\n",
    "#         print(\"parameters updated\")\n",
    "#         pyro.get_param_store().save(\"./param/practice3.save\")\n",
    "#         start_loss = total_epoch_loss_train\n",
    "        \n",
    "#     if epoch == 100:\n",
    "#         lr = lr*0.8\n",
    "#         print(\"learning rate decreased\")\n",
    "#         optimizer = Adam({\"lr\":lr})\n",
    "#         svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "#         epoch = 0\n",
    "#     epoch += 1\n",
    "    \n",
    "#     if lr <= lr*(0.8)**5:\n",
    "#         lr = 0.008\n",
    "#         print(\"learning rate increased\")\n",
    "#         optimizer = Adam({\"lr\":lr})\n",
    "#         svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "    \n",
    "#     if j % 5 == 0:\n",
    "#         pred = []\n",
    "#         true=[]\n",
    "#         models = guide(None,None)\n",
    "#         for batch_id, data_test in enumerate(batch_test):\n",
    "#             pred.append(models(data_test[0], data_test[1]).cpu().detach())\n",
    "#             true.append(torch.tensor(data_test[1]))\n",
    "\n",
    "#         MAE = mean_absolute_error(torch.cat(true), torch.cat(pred))\n",
    "#         print(\"Epoch \", j, \" Loss \", total_epoch_loss_train, \"test MAE\", MAE)\n",
    "#     else:\n",
    "#         print(\"Epoch \", j, \" Loss \", total_epoch_loss_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pyro.get_param_store().load(\"penultimate_BNN.save\")\n",
    "for name in pyro.get_param_store().get_all_param_names():\n",
    "    print((name, pyro.param(name).data.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling \n",
    "sample networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_samples = 10\n",
    "sampled_models = [guide(None, None) for _ in range(num_samples)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess Performance\n",
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "predictions_val = []\n",
    "labels_val = []\n",
    "\n",
    "for model in tqdm_notebook(sampled_models):\n",
    "    pred_val = []\n",
    "    true_val = []\n",
    "    for batch_id, data_val in enumerate(batch_val):\n",
    "        pred_val.append(model(data_val[0], data_val[1]).cpu().detach())\n",
    "        true_val.append(torch.tensor(data_val[1]))\n",
    "    predictions_val.append(torch.cat(pred_val).numpy())\n",
    "    labels_val.append(torch.cat(true_val).numpy())\n",
    "    \n",
    "predictions_val, labels_val = np.array(predictions_val), np.array(labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.metrics import (mean_absolute_error,\n",
    "                             mean_squared_error,\n",
    "                             r2_score,\n",
    "                             median_absolute_error)\n",
    "import seaborn as sns\n",
    "\n",
    "# Make the predictions\n",
    "targets_pred = predictions_val.mean(axis=0).flatten()\n",
    "targets_val = labels_val.mean(axis=0).flatten() \n",
    "residuals = (targets_pred - targets_val)#.numpy()\n",
    "stdevs = predictions_val.std(axis=0)\n",
    "\n",
    "# Plot\n",
    "lims = [-4, 4]\n",
    "grid = sns.jointplot(targets_val.reshape(-1), targets_pred,\n",
    "                     kind='hex',\n",
    "                     bins='log',\n",
    "                     extent=lims+lims)\n",
    "ax = grid.ax_joint\n",
    "_ = ax.set_xlim(lims)\n",
    "_ = ax.set_ylim(lims)\n",
    "_ = ax.plot(lims, lims, '--')\n",
    "_ = ax.set_xlabel('DFT $\\Delta$E [eV]')\n",
    "_ = ax.set_ylabel('%s $\\Delta$E [eV]' % model_name)\n",
    "\n",
    "# Calculate the error metrics\n",
    "mae = mean_absolute_error(targets_val, targets_pred)\n",
    "rmse = np.sqrt(mean_squared_error(targets_val, targets_pred))\n",
    "mdae = median_absolute_error(targets_val, targets_pred)\n",
    "marpd = np.abs(2 * residuals /\n",
    "               (np.abs(targets_pred) + np.abs(targets_val.reshape(-1)))\n",
    "               ).mean() * 100\n",
    "r2 = r2_score(targets_val, targets_pred)\n",
    "corr = np.corrcoef(targets_val.reshape(-1), targets_pred)[0, 1]\n",
    "\n",
    "# Report\n",
    "text = ('    n = %i\\n' % len(targets_val) +\n",
    "        '    MAE = %.2f eV\\n' % mae + \n",
    "        '    RMSE = %.2f eV\\n' % rmse + \n",
    "        '    MDAE = %.2f eV\\n' % mdae + \n",
    "        '    MARPD = %i%%\\n' % marpd + \n",
    "        '    R$^2$ = %.2f\\n' % r2 +\n",
    "        '    Pearson\\'s = %.2f' % corr)\n",
    "_ = ax.text(x=lims[0], y=lims[1], s=text,\n",
    "            horizontalalignment='left',\n",
    "            verticalalignment='top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "def calculate_density(percentile):\n",
    "    num_within_quantile = 0\n",
    "    for stdev, resid in zip(stdevs, residuals):\n",
    "        norm = stats.norm(loc=0, scale=stdev)\n",
    "        lower_bound = norm.ppf(0.5-percentile/2)\n",
    "        upper_bound = norm.ppf(0.5+percentile/2)\n",
    "        if lower_bound <= resid <= upper_bound:\n",
    "            num_within_quantile += 1\n",
    "    density = num_within_quantile / len(residuals)\n",
    "    return density\n",
    "\n",
    "predicted_pi = np.linspace(0, 1, 20)\n",
    "observed_pi = [calculate_density(quantile)\n",
    "               for quantile in tqdm_notebook(predicted_pi, desc='Calibration')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "\n",
    "# Plot settings\n",
    "figsize = (4, 4)\n",
    "\n",
    "# Plot the calibration curve\n",
    "fig_cal = plt.figure(figsize=figsize)\n",
    "ax_ideal = sns.lineplot([0, 1], [0, 1], label='ideal')\n",
    "_ = ax_ideal.lines[0].set_linestyle('--')\n",
    "ax_gp = sns.lineplot(predicted_pi, observed_pi, label=model_name)\n",
    "ax_fill = plt.fill_between(predicted_pi, predicted_pi, observed_pi,\n",
    "                           alpha=0.2, label='miscalibration area')\n",
    "_ = ax_ideal.set_xlabel('Expected prediction interval')\n",
    "_ = ax_ideal.set_ylabel('Observed prediction interval')\n",
    "_ = ax_ideal.set_xlim([0, 1])\n",
    "_ = ax_ideal.set_ylim([0, 1])\n",
    "\n",
    "# Calculate the miscalibration area.\n",
    "polygon_points = []\n",
    "for point in zip(predicted_pi, observed_pi):\n",
    "    polygon_points.append(point)\n",
    "for point in zip(reversed(predicted_pi), reversed(predicted_pi)):\n",
    "    polygon_points.append(point)\n",
    "polygon_points.append((predicted_pi[0], observed_pi[0]))\n",
    "polygon = Polygon(polygon_points)\n",
    "miscalibration_area = polygon.area\n",
    "\n",
    "# Annotate the plot with the miscalibration area\n",
    "plt.text(x=0.95, y=0.05,\n",
    "         s='Miscalibration area = %.2f' % miscalibration_area,\n",
    "         verticalalignment='bottom',\n",
    "         horizontalalignment='right')\n",
    "\n",
    "\n",
    "# Plot sharpness curve\n",
    "xlim = [0, 1.]\n",
    "fig_sharp = plt.figure(figsize=figsize)\n",
    "ax_sharp = sns.distplot(stdevs, kde=False, norm_hist=True)\n",
    "ax_sharp.set_xlim(xlim)\n",
    "ax_sharp.set_xlabel('Predicted standard deviation (eV)')\n",
    "ax_sharp.set_ylabel('Normalized frequency')\n",
    "ax_sharp.set_yticklabels([])\n",
    "ax_sharp.set_yticks([])\n",
    "\n",
    "# Calculate and report sharpness\n",
    "sharpness = np.sqrt(np.mean(stdevs**2))\n",
    "_ = ax_sharp.axvline(x=sharpness, label='sharpness')\n",
    "if sharpness < (xlim[0] + xlim[1]) / 2:\n",
    "    text = '\\n  Sharpness = %.2f eV' % sharpness\n",
    "    h_align = 'left'\n",
    "else:\n",
    "    text = '\\nSharpness = %.2f eV  ' % sharpness\n",
    "    h_align = 'right'\n",
    "_ = ax_sharp.text(x=sharpness, y=ax_sharp.get_ylim()[1],\n",
    "                  s=text,\n",
    "                  verticalalignment='top',\n",
    "                  horizontalalignment=h_align)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "predictions_test = []\n",
    "labels_test = []\n",
    "for model in tqdm_notebook(sampled_models):\n",
    "    pred_test = []\n",
    "    true_test = []\n",
    "    for batch_id, data_test in enumerate(batch_test):\n",
    "        pred_test.append(model(data_test[0], data_test[1]).cpu().detach())\n",
    "        true_test.append(torch.tensor(data_test[1]))\n",
    "    predictions_test.append(torch.cat(pred_test).numpy())\n",
    "    labels_test.append(torch.cat(true_test).numpy())\n",
    "\n",
    "predictions_test, labels_test = np.array(predictions_test), np.array(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.metrics import (mean_absolute_error,\n",
    "                             mean_squared_error,\n",
    "                             r2_score,\n",
    "                             median_absolute_error)\n",
    "import seaborn as sns\n",
    "\n",
    "# Make the predictions\n",
    "targets_pred = predictions_test.mean(axis=0).flatten()\n",
    "targets_val = labels_test.mean(axis=0).flatten() \n",
    "residuals = (targets_pred - targets_val)#.numpy()\n",
    "stdevs = predictions_test.std(axis=0)\n",
    "\n",
    "# Plot\n",
    "lims = [-4, 4]\n",
    "grid = sns.jointplot(targets_val.reshape(-1), targets_pred,\n",
    "                     kind='hex',\n",
    "                     bins='log',\n",
    "                     extent=lims+lims)\n",
    "ax = grid.ax_joint\n",
    "_ = ax.set_xlim(lims)\n",
    "_ = ax.set_ylim(lims)\n",
    "_ = ax.plot(lims, lims, '--')\n",
    "_ = ax.set_xlabel('DFT $\\Delta$E [eV]')\n",
    "_ = ax.set_ylabel('%s $\\Delta$E [eV]' % model_name)\n",
    "\n",
    "# Calculate the error metrics\n",
    "mae = mean_absolute_error(targets_val, targets_pred)\n",
    "rmse = np.sqrt(mean_squared_error(targets_val, targets_pred))\n",
    "mdae = median_absolute_error(targets_val, targets_pred)\n",
    "marpd = np.abs(2 * residuals /\n",
    "               (np.abs(targets_pred) + np.abs(targets_val.reshape(-1)))\n",
    "               ).mean() * 100\n",
    "r2 = r2_score(targets_val, targets_pred)\n",
    "corr = np.corrcoef(targets_val.reshape(-1), targets_pred)[0, 1]\n",
    "\n",
    "# Report\n",
    "text = ('    n = %i\\n' % len(targets_val) +\n",
    "        '    MAE = %.2f eV\\n' % mae + \n",
    "        '    RMSE = %.2f eV\\n' % rmse + \n",
    "        '    MDAE = %.2f eV\\n' % mdae + \n",
    "        '    MARPD = %i%%\\n' % marpd + \n",
    "        '    R$^2$ = %.2f\\n' % r2 +\n",
    "        '    Pearson\\'s = %.2f' % corr)\n",
    "_ = ax.text(x=lims[0], y=lims[1], s=text,\n",
    "            horizontalalignment='left',\n",
    "            verticalalignment='top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "def calculate_density(percentile):\n",
    "    num_within_quantile = 0\n",
    "    for stdev, resid in zip(stdevs, residuals):\n",
    "        norm = stats.norm(loc=0, scale=stdev)\n",
    "        lower_bound = norm.ppf(0.5-percentile/2)\n",
    "        upper_bound = norm.ppf(0.5+percentile/2)\n",
    "        if lower_bound <= resid <= upper_bound:\n",
    "            num_within_quantile += 1\n",
    "    density = num_within_quantile / len(residuals)\n",
    "    return density\n",
    "\n",
    "predicted_pi = np.linspace(0, 1, 20)\n",
    "observed_pi = [calculate_density(quantile)\n",
    "               for quantile in tqdm_notebook(predicted_pi, desc='Calibration')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "\n",
    "# Plot settings\n",
    "figsize = (4, 4)\n",
    "\n",
    "# Plot the calibration curve\n",
    "fig_cal = plt.figure(figsize=figsize)\n",
    "ax_ideal = sns.lineplot([0, 1], [0, 1], label='ideal')\n",
    "_ = ax_ideal.lines[0].set_linestyle('--')\n",
    "ax_gp = sns.lineplot(predicted_pi, observed_pi, label=model_name)\n",
    "ax_fill = plt.fill_between(predicted_pi, predicted_pi, observed_pi,\n",
    "                           alpha=0.2, label='miscalibration area')\n",
    "_ = ax_ideal.set_xlabel('Expected prediction interval')\n",
    "_ = ax_ideal.set_ylabel('Observed prediction interval')\n",
    "_ = ax_ideal.set_xlim([0, 1])\n",
    "_ = ax_ideal.set_ylim([0, 1])\n",
    "\n",
    "# Calculate the miscalibration area.\n",
    "polygon_points = []\n",
    "for point in zip(predicted_pi, observed_pi):\n",
    "    polygon_points.append(point)\n",
    "for point in zip(reversed(predicted_pi), reversed(predicted_pi)):\n",
    "    polygon_points.append(point)\n",
    "polygon_points.append((predicted_pi[0], observed_pi[0]))\n",
    "polygon = Polygon(polygon_points)\n",
    "miscalibration_area = polygon.area\n",
    "\n",
    "# Annotate the plot with the miscalibration area\n",
    "plt.text(x=0.95, y=0.05,\n",
    "         s='Miscalibration area = %.2f' % miscalibration_area,\n",
    "         verticalalignment='bottom',\n",
    "         horizontalalignment='right')\n",
    "\n",
    "\n",
    "# Plot sharpness curve\n",
    "xlim = [0, 1.]\n",
    "fig_sharp = plt.figure(figsize=figsize)\n",
    "ax_sharp = sns.distplot(stdevs, kde=False, norm_hist=True)\n",
    "ax_sharp.set_xlim(xlim)\n",
    "ax_sharp.set_xlabel('Predicted standard deviation (eV)')\n",
    "ax_sharp.set_ylabel('Normalized frequency')\n",
    "ax_sharp.set_yticklabels([])\n",
    "ax_sharp.set_yticks([])\n",
    "\n",
    "# Calculate and report sharpness\n",
    "sharpness = np.sqrt(np.mean(stdevs**2))\n",
    "_ = ax_sharp.axvline(x=sharpness, label='sharpness')\n",
    "if sharpness < (xlim[0] + xlim[1]) / 2:\n",
    "    text = '\\n  Sharpness = %.2f eV' % sharpness\n",
    "    h_align = 'left'\n",
    "else:\n",
    "    text = '\\nSharpness = %.2f eV  ' % sharpness\n",
    "    h_align = 'right'\n",
    "_ = ax_sharp.text(x=sharpness, y=ax_sharp.get_ylim()[1],\n",
    "                  s=text,\n",
    "                  verticalalignment='top',\n",
    "                  horizontalalignment=h_align)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error-bar figure\n",
    "We concede that calibration curves and sharpness distributions are new concepts in the field of catalysis, and that a simple parity plot with error bars is more intuitive. As such, we create a few examples of error bar parities to help readers connect those incumbent ideas with the newer ideas of calibration and sharpness.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Pull a random sample of the data, because plotting thousands of these at once would look absurd\n",
    "all_predictions = list(zip(targets_pred, targets_test.reshape(-1), stdevs))\n",
    "samples = random.sample(all_predictions, k=20)\n",
    "\n",
    "# Parse the samples\n",
    "_preds, _targets, _stdevs = zip(*samples)\n",
    "_preds = np.array(_preds)\n",
    "_targets = np.array(_targets)\n",
    "_stdevs = np.array(_stdevs)\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "_ = plt.errorbar(_targets, _preds, yerr=2*_stdevs, fmt='o')\n",
    "ax = plt.gca()\n",
    "\n",
    "# Make a parity line\n",
    "lims = [-2, 2]\n",
    "_ = ax.plot(lims, lims, '--')\n",
    "\n",
    "# Format\n",
    "_ = ax.set_xlim(lims)\n",
    "_ = ax.set_ylim(lims)\n",
    "_ = ax.set_xticks(list(range(-2, 3)))\n",
    "_ = ax.set_yticks(list(range(-2, 3)))\n",
    "_ = ax.set_xlabel('DFT $\\Delta$E [eV]')\n",
    "_ = ax.set_ylabel('%s $\\Delta$E [eV]' % model_name)\n",
    "\n",
    "# Save\n",
    "_ = plt.savefig('error_bar_parity.pdf', dpi=300, bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the data\n",
    "We need to save the prediction data with the `pickle` module, so we can compare the effects of different prediction methods and different dropout levels in one plot, using another notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as pickle to be plotted with in the same graph as others\n",
    "with open('bnn_old_d%i.pkl' % dropout_int, 'wb') as saveplot:\n",
    "    pickle.dump((predictions, targets_val), saveplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaspy_ktran",
   "language": "python",
   "name": "gaspy_ktran"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
