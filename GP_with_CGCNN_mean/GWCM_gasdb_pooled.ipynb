{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize and Train CGCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Automatically search for an NVIDIA GPU and use it. If not, then use CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('Using GPU')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load all of our preprocessed and split data from our cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "# Label to use for this model in the plots\n",
    "model_name = 'GP-with-CGCNN-mean'\n",
    "\n",
    "with open('../preprocessing/sdt/gasdb/feature_dimensions.pkl', 'rb') as file_handle:\n",
    "    orig_atom_fea_len, nbr_fea_len = pickle.load(file_handle)\n",
    "\n",
    "with open('../preprocessing/splits_gasdb.pkl', 'rb') as file_handle:\n",
    "    splits = pickle.load(file_handle)\n",
    "\n",
    "docs_train = splits['docs_train']\n",
    "docs_val = splits['docs_val']\n",
    "sdts_train, sdts_val = splits['sdts_train'], splits['sdts_val']\n",
    "targets_train, targets_val = splits['targets_train'], splits['targets_val']\n",
    "\n",
    "# Where we put the intermediate results for this notebook\n",
    "prefix = 'gasdb_pooled/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialize the CGCNN `net` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "# import skorch.callbacks.base\n",
    "from skorch import callbacks  # needs skorch >= 0.4  \n",
    "from skorch import NeuralNetRegressor\n",
    "from skorch.dataset import CVSplit\n",
    "from cgcnn.model import CrystalGraphConvNet\n",
    "from cgcnn.data import collate_pool, MergeDataset\n",
    "\n",
    "\n",
    "# Callback to checkpoint parameters every time there is a new best for validation loss\n",
    "cp = callbacks.Checkpoint(monitor='valid_loss_best', fn_prefix=prefix+'valid_best_')\n",
    "\n",
    "# Callback to load the checkpoint with the best validation loss at the end of training\n",
    "class train_end_load_best_valid_loss(callbacks.base.Callback):\n",
    "    def on_train_end(self, net, X, y):\n",
    "        net.load_params(prefix+'valid_best_params.pt')\n",
    "load_best_valid_loss = train_end_load_best_valid_loss()\n",
    "\n",
    "# Callback to set the learning rate dynamically\n",
    "LR_schedule = callbacks.lr_scheduler.LRScheduler('MultiStepLR', milestones=[100], gamma=0.1)\n",
    "\n",
    "net = NeuralNetRegressor(\n",
    "    CrystalGraphConvNet,\n",
    "    module__orig_atom_fea_len=orig_atom_fea_len,\n",
    "    module__nbr_fea_len=nbr_fea_len,\n",
    "    batch_size=214,\n",
    "    module__classification=False,\n",
    "    lr=0.0056,\n",
    "    max_epochs=150,\n",
    "    module__atom_fea_len=46,\n",
    "    module__h_fea_len=83,\n",
    "    module__n_conv=8,\n",
    "    module__n_h=4,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__pin_memory=True,\n",
    "    iterator_train__num_workers=0,\n",
    "    iterator_train__collate_fn=collate_pool,\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_valid__pin_memory=True,\n",
    "    iterator_valid__num_workers=0,\n",
    "    iterator_valid__collate_fn=collate_pool,\n",
    "    iterator_valid__shuffle=False,\n",
    "    device=device,\n",
    "    criterion=torch.nn.L1Loss,\n",
    "    dataset=MergeDataset,\n",
    "    callbacks=[cp, load_best_valid_loss, LR_schedule]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training the CGCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.initialize()\n",
    "net.fit(sdts_train, targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart training in case first round was cut off\n",
    "net.partial_fit(sdts_train, targets_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ...or load whatever is cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.initialize()\n",
    "net.load_params(f_history=prefix+'valid_best_history.json',\n",
    "                f_optimizer=prefix+'valid_best_optimizer.pt', \n",
    "                f_params=prefix+'valid_best_params.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize and Train GP-rbf with CGCNN Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "\n",
    "\n",
    "# Get CGCNN predictions on sdts_val, and sdts_train\n",
    "targets_pred = net.predict(sdts_val).reshape(-1)\n",
    "targets_pred_train = net.predict(sdts_train).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fingerprints data\n",
    "fingerprints_train_raw = splits['fingerprints_train']\n",
    "fingerprints_val_raw = splits['fingerprints_val']\n",
    "\n",
    "# Define all the adsorbates\n",
    "adsorbates = list({doc['adsorbate'] for doc in docs_val})\n",
    "adsorbates.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the fingerprints\n",
    "scaler = StandardScaler()\n",
    "fingerprints_train = scaler.fit_transform(fingerprints_train_raw)\n",
    "fingerprints_val = scaler.transform(fingerprints_val_raw)\n",
    "\n",
    "# Make torch.Tensor version of data for GPyTorch\n",
    "fingerprints_train = torch.Tensor(fingerprints_train).contiguous()\n",
    "fingerprints_val = torch.Tensor(fingerprints_val)\n",
    "targets_train_gp = torch.Tensor(targets_train.reshape(-1))\n",
    "targets_val_gp = torch.Tensor(targets_val.reshape(-1))\n",
    "\n",
    "# Transform targets for GP with nonzero mean\n",
    "targets_train_gp = targets_train_gp - torch.Tensor(targets_pred_train)\n",
    "targets_val_gp = targets_val_gp - torch.Tensor(targets_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "\n",
    "\n",
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training the GP\n",
    "\n",
    "%matplotlib inline\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(fingerprints_train, targets_train_gp, likelihood)\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam([{'params': model.parameters()}], lr=0.1)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "# Function to make dynamic learning curve\n",
    "def live_plot(data_dict, figsize=(7, 5), title=''):\n",
    "    ''' Credit to Ziofil on StackOverflow '''\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for label, data in data_dict.items():\n",
    "        plt.plot(data, label=label)\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.legend(loc='center left')  # the plot evolves to the right\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylim(0, max(max(data) for data in data_dict.values()))\n",
    "    plt.show()\n",
    "\n",
    "def train(training_iterations=25):\n",
    "    # Train the model\n",
    "    learning_curve_data = defaultdict(list)\n",
    "    for i in range(training_iterations):\n",
    "        # Zero backprop gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Get output from model\n",
    "        output = model(fingerprints_train)\n",
    "        # Calc loss and backprop derivatives\n",
    "        loss = -mll(output, targets_train_gp)\n",
    "        loss.backward()\n",
    "        # Update the learning curve\n",
    "        learning_curve_data['Loss'].append(loss.item())\n",
    "        live_plot(learning_curve_data)\n",
    "        optimizer.step()\n",
    "\n",
    "%time train(23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess Performance: GP-rbf with CGCNN Mean in Transformed Output Space\n",
    "## All adsorbates\n",
    "This latest chunk of data came from multiple adsorbates. To start simple, let's just plot everything within a single pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Make the predictions\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    %time preds = model(fingerprints_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting results (transformed output space)\n",
    "\n",
    "# Parse the predictions\n",
    "targets_pred_gp = preds.mean\n",
    "\n",
    "# Plot\n",
    "lims = [-4, 4]\n",
    "grid = sns.jointplot(targets_val_gp.reshape(-1),\n",
    "                     targets_pred_gp.reshape(-1),\n",
    "                     kind='hex',\n",
    "                     bins='log',\n",
    "                     extent=lims*2)\n",
    "ax = grid.ax_joint\n",
    "_ = ax.set_xlim(lims)\n",
    "_ = ax.set_ylim(lims)\n",
    "_ = ax.plot(lims, lims, '--')\n",
    "_ = ax.set_xlabel('DFT $\\Delta$E [eV]')\n",
    "_ = ax.set_ylabel('%s $\\Delta$E [eV]' % model_name)\n",
    "\n",
    "# Calculate the error metrics\n",
    "mae = mean_absolute_error(targets_val_gp, targets_pred_gp)\n",
    "rmse = np.sqrt(mean_squared_error(targets_val_gp, targets_pred_gp))\n",
    "r2 = r2_score(targets_val_gp, targets_pred_gp)\n",
    "\n",
    "# Report\n",
    "text = ('    n = %i\\n'\n",
    "        '    MAE = %.2f eV\\n'\n",
    "        '    RMSE = %.2f eV\\n'\n",
    "        '    R$^2$ = %.2f'\n",
    "        % (len(targets_val_gp), mae, rmse, r2))\n",
    "_ = ax.text(x=lims[0], y=lims[1], s=text,\n",
    "            horizontalalignment='left',\n",
    "            verticalalignment='top')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess Performance: GP-rbf with CGCNN Mean in Original Output Space\n",
    "## All adsorbates\n",
    "This latest chunk of data came from multiple adsorbates. To start simple, let's just plot everything within a single pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting results (original output space)\n",
    "\n",
    "# Transform outputs\n",
    "targets_val_gp_orig = targets_val_gp + torch.Tensor(targets_pred)\n",
    "targets_pred_gp_orig = targets_pred_gp + torch.Tensor(targets_pred)\n",
    "\n",
    "# Plot\n",
    "lims = [-4, 4]\n",
    "grid = sns.jointplot(targets_val_gp_orig.reshape(-1),\n",
    "                     targets_pred_gp_orig.reshape(-1),\n",
    "                     kind='hex',\n",
    "                     bins='log',\n",
    "                     extent=lims*2)\n",
    "ax = grid.ax_joint\n",
    "_ = ax.set_xlim(lims)\n",
    "_ = ax.set_ylim(lims)\n",
    "_ = ax.plot(lims, lims, '--')\n",
    "_ = ax.set_xlabel('DFT $\\Delta$E [eV]')\n",
    "_ = ax.set_ylabel('%s $\\Delta$E [eV]' % model_name)\n",
    "\n",
    "# Calculate the error metrics\n",
    "mae = mean_absolute_error(targets_val_gp_orig, targets_pred_gp_orig)\n",
    "rmse = np.sqrt(mean_squared_error(targets_val_gp_orig, targets_pred_gp_orig))\n",
    "r2 = r2_score(targets_val_gp_orig, targets_pred_gp_orig)\n",
    "\n",
    "# Report\n",
    "text = ('    n = %i\\n'\n",
    "        '    MAE = %.2f eV\\n'\n",
    "        '    RMSE = %.2f eV\\n'\n",
    "        '    R$^2$ = %.2f'\n",
    "        % (len(targets_val_gp_orig), mae, rmse, r2))\n",
    "_ = ax.text(x=lims[0], y=lims[1], s=text,\n",
    "            horizontalalignment='left',\n",
    "            verticalalignment='top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing calibration\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "\n",
    "residuals = (targets_pred_gp_orig - targets_val_gp_orig).detach().numpy()\n",
    "stdevs = preds.stddev.detach().numpy()\n",
    "\n",
    "def calculate_density(percentile):\n",
    "    num_within_quantile = 0\n",
    "    for stdev, resid in zip(stdevs, residuals):\n",
    "        norm = stats.norm(loc=0, scale=stdev)\n",
    "        lower_bound = norm.ppf(0.5-percentile/2)\n",
    "        upper_bound = norm.ppf(0.5+percentile/2)\n",
    "        if lower_bound <= resid <= upper_bound:\n",
    "            num_within_quantile += 1\n",
    "    density = num_within_quantile / len(residuals)\n",
    "    return density\n",
    "\n",
    "predicted_pi = np.linspace(0, 1, 20)\n",
    "observed_pi = [calculate_density(quantile)\n",
    "               for quantile in tqdm_notebook(predicted_pi, desc='Calibration')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "\n",
    "# Plot settings\n",
    "figsize = (4, 4)\n",
    "\n",
    "# Plot the calibration curve\n",
    "fig_cal = plt.figure(figsize=figsize)\n",
    "ax_ideal = sns.lineplot([0, 1], [0, 1], label='ideal')\n",
    "_ = ax_ideal.lines[0].set_linestyle('--')\n",
    "ax_gp = sns.lineplot(predicted_pi, observed_pi, label=model_name)\n",
    "ax_fill = plt.fill_between(predicted_pi, predicted_pi, observed_pi,\n",
    "                           alpha=0.2, label='miscalibration area')\n",
    "_ = ax_ideal.set_xlabel('Expected prediction interval')\n",
    "_ = ax_ideal.set_ylabel('Observed prediction interval')\n",
    "_ = ax_ideal.set_xlim([0, 1])\n",
    "_ = ax_ideal.set_ylim([0, 1])\n",
    "\n",
    "# Calculate the miscalibration area.\n",
    "polygon_points = []\n",
    "for point in zip(predicted_pi, observed_pi):\n",
    "    polygon_points.append(point)\n",
    "for point in zip(reversed(predicted_pi), reversed(predicted_pi)):\n",
    "    polygon_points.append(point)\n",
    "polygon_points.append((predicted_pi[0], observed_pi[0]))\n",
    "polygon = Polygon(polygon_points)\n",
    "miscalibration_area = polygon.area\n",
    "\n",
    "# Annotate the plot with the miscalibration area\n",
    "plt.text(x=0.95, y=0.05,\n",
    "         s='Miscalibration area = %.2f' % miscalibration_area,\n",
    "         verticalalignment='bottom',\n",
    "         horizontalalignment='right')\n",
    "\n",
    "# Plot sharpness curve\n",
    "xlim = [0., 1.5]\n",
    "fig_sharp = plt.figure(figsize=figsize)\n",
    "ax_sharp = sns.distplot(stdevs, kde=False, norm_hist=True)\n",
    "ax_sharp.set_xlim(xlim)\n",
    "ax_sharp.set_xlabel('Predicted standard deviations (eV)')\n",
    "ax_sharp.set_ylabel('Normalized frequency')\n",
    "ax_sharp.set_yticklabels([])\n",
    "ax_sharp.set_yticks([])\n",
    "\n",
    "# Calculate and report sharpness\n",
    "sharpness = np.sqrt(np.mean(stdevs**2))\n",
    "_ = ax_sharp.axvline(x=sharpness, label='sharpness')\n",
    "if sharpness < (xlim[0] + xlim[1]) / 2:\n",
    "    text = '\\n  Sharpness = %.2f eV' % sharpness\n",
    "    h_align = 'left'\n",
    "else:\n",
    "    text = '\\nSharpness = %.2f eV  ' % sharpness\n",
    "    h_align = 'right'\n",
    "_ = ax_sharp.text(x=sharpness, y=ax_sharp.get_ylim()[1],\n",
    "                  s=text,\n",
    "                  verticalalignment='top',\n",
    "                  horizontalalignment=h_align)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miscalibration_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results-by-adsorbate\n",
    "Let's dig into details and see how our results turned out for each adsorbate. Note that this section shows the results from a single model trained on a pooled dataset. Only the performance metrics are partitioned by adsorbate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SeabornFig2Grid():\n",
    "    '''\n",
    "    Credit goes to ImportanceOfBeingErnest on StackOverflow\n",
    "    https://stackoverflow.com/questions/35042255/how-to-plot-multiple-seaborn-jointplot-in-subplot\n",
    "    '''\n",
    "\n",
    "    def __init__(self, seaborngrid, fig, subplot_spec):\n",
    "        self.fig = fig\n",
    "        self.sg = seaborngrid\n",
    "        self.subplot = subplot_spec\n",
    "        if isinstance(self.sg, sns.axisgrid.FacetGrid) or \\\n",
    "            isinstance(self.sg, sns.axisgrid.PairGrid):\n",
    "            self._movegrid()\n",
    "        elif isinstance(self.sg, sns.axisgrid.JointGrid):\n",
    "            self._movejointgrid()\n",
    "        self._finalize()\n",
    "\n",
    "    def _movegrid(self):\n",
    "        \"\"\" Move PairGrid or Facetgrid \"\"\"\n",
    "        self._resize()\n",
    "        n = self.sg.axes.shape[0]\n",
    "        m = self.sg.axes.shape[1]\n",
    "        self.subgrid = gridspec.GridSpecFromSubplotSpec(n,m, subplot_spec=self.subplot)\n",
    "        for i in range(n):\n",
    "            for j in range(m):\n",
    "                self._moveaxes(self.sg.axes[i,j], self.subgrid[i,j])\n",
    "\n",
    "    def _movejointgrid(self):\n",
    "        \"\"\" Move Jointgrid \"\"\"\n",
    "        h= self.sg.ax_joint.get_position().height\n",
    "        h2= self.sg.ax_marg_x.get_position().height\n",
    "        r = int(np.round(h/h2))\n",
    "        self._resize()\n",
    "        self.subgrid = gridspec.GridSpecFromSubplotSpec(r+1,r+1, subplot_spec=self.subplot)\n",
    "\n",
    "        self._moveaxes(self.sg.ax_joint, self.subgrid[1:, :-1])\n",
    "        self._moveaxes(self.sg.ax_marg_x, self.subgrid[0, :-1])\n",
    "        self._moveaxes(self.sg.ax_marg_y, self.subgrid[1:, -1])\n",
    "\n",
    "    def _moveaxes(self, ax, gs):\n",
    "        #https://stackoverflow.com/a/46906599/4124317\n",
    "        ax.remove()\n",
    "        ax.figure=self.fig\n",
    "        self.fig.axes.append(ax)\n",
    "        self.fig.add_axes(ax)\n",
    "        ax._subplotspec = gs\n",
    "        ax.set_position(gs.get_position(self.fig))\n",
    "        ax.set_subplotspec(gs)\n",
    "\n",
    "    def _finalize(self):\n",
    "        plt.close(self.sg.fig)\n",
    "        self.fig.canvas.mpl_connect(\"resize_event\", self._resize)\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def _resize(self, evt=None):\n",
    "        self.sg.fig.set_size_inches(self.fig.get_size_inches())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "\n",
    "# Prepare figure for all adsorbates\n",
    "fig = plt.figure(figsize=(20, 4))\n",
    "gs = gridspec.GridSpec(1, len(adsorbates))\n",
    "\n",
    "# Parse out the data for each adsorbate\n",
    "for i, ads in enumerate(adsorbates):\n",
    "    _targets_val = []\n",
    "    _targets_pred = []\n",
    "    for doc, target, pred in zip(docs_val, targets_val_gp_orig, targets_pred_gp_orig):\n",
    "        if doc['adsorbate'] == ads:\n",
    "            _targets_val.append(target)\n",
    "            _targets_pred.append(pred)\n",
    "    _targets_val = np.array(_targets_val).reshape(-1)\n",
    "    _targets_pred = np.array(_targets_pred).reshape(-1)\n",
    "\n",
    "    # Plot accuracy\n",
    "    lims = [-5, 5]\n",
    "    grid = sns.jointplot(_targets_val, _targets_pred,\n",
    "                         kind='hex',\n",
    "                         bins='log',\n",
    "                         extent=lims*2)\n",
    "    ax = grid.ax_joint\n",
    "    _ = ax.set_xlim(lims)\n",
    "    _ = ax.set_ylim(lims)\n",
    "    _ = ax.plot(lims, lims, '--')\n",
    "    _ = ax.set_xlabel('DFT $\\Delta$E [eV]')\n",
    "    _ = ax.set_ylabel('%s $\\Delta$E [eV]' % model_name)\n",
    "    _ = ax.set_title(ads)\n",
    "\n",
    "    # Calculate + report metrics\n",
    "    mae = mean_absolute_error(_targets_val, _targets_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(_targets_val, _targets_pred))\n",
    "    r2 = r2_score(_targets_val, _targets_pred)\n",
    "    grid.ax_marg_x.text(x=lims[0], y=0,\n",
    "                        verticalalignment='bottom',\n",
    "                        s='%s\\n' % ads)\n",
    "    text = ('  n = %i\\n'\n",
    "            '  MAE = %.2f eV\\n'\n",
    "            '  RMSE = %.2f eV\\n'\n",
    "            '  R$^2$ = %.2f'\n",
    "            % (len(_targets_val), mae, rmse, r2))\n",
    "    ax.text(x=lims[0], y=lims[1], s=text,\n",
    "            horizontalalignment='left',\n",
    "            verticalalignment='top')\n",
    "\n",
    "    # Put the figure into the subplot\n",
    "    sfg = SeabornFig2Grid(grid, fig, gs[i])\n",
    "gs.tight_layout(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ktran",
   "language": "python",
   "name": "ktran"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
